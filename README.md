---
## 인공지능 팀플
- 연도: 2024
- 학교: 한양대학교
- 학과명: 정보공학전공
- 수업명: 인공지능
- 교수명: 정철현 교수
- 프로젝트 제목: 금융실무자를 위한 인공지능 챗봇 개발
- 팀원명: 김재현 (2020023481), 김재현 (2021056617), 이병주 (2021089961), 정민혁 (2021053436)
- Github 이메일 주소: owogus29@naver.com, nyyynyyys@naver.com, bobby0908@hanyang.ac.kr, sony345@hanyang.ac.kr

---

### 개요

1. **문제상황이 무엇인가?**
    - 금융실명제는 실지명의가 확인된 고객을 대상으로 금융거래를 실시하는 제도 및 법률임. 금융실명제는 금융업무에 있어서 시작이 되는 매우 중요한 법률임. 은행의 실무자들이 숙지하기엔 다양한 케이스가 많은 반면, 현재 대출상담 등 상품을 상담하기 위한 금융회사의 챗봇은 다수 존재하지만, 금융실무자를 위한 챗봇은 존재하지 않기에, 법률리스크를 가지게 된다.
2. **어떻게 개선하고자 하는가?**
    - 금융 실무자를 위해 특화된 챗봇을 만들고, 금융시장 질서에 이바지하고자 함.
3. **주어진 조건이 무엇인가?**
    - 제한된 리소스 : LLM 학습을 할 정도 성능의 GPU를 보유하고 있지 않음
    - 시간 제한 : LLM 성능을 개선시키기 위해서 파인튜닝을 충분히 수행할 만큼의 시간이 없음
    - 학습 데이터 : 특정 도메인에 특화된 모델을 만들기 위한 데이터 수집 및 가공 방법 필요

### 추진방안

4. **그 조건이기 때문에 어떤 인공지능을 선택했는가? / 해당 인공지능을 우리의 상황에 적용하기 위해서는 어떤 노력을 해야하는가?**
    - 처음에는 Stanford-Alpaca 모델의 공개된 학습 데이터셋을 기반으로 추가 데이터를 넣어서 학습을(Fully-Finetuning) 진행하려고 했음
        - 그러나 코랩 기준 1epoch 당 8시간이 넘게 걸려서 하이퍼파라미터 튜닝 등을 고려했을때 현실적으로 어렵다고 판단
        - **파인튜닝 (Fine-Tuning)**: 이미 학습된 모델(기본 모델)을 특정 작업이나 데이터셋에 맞게 추가 학습시키는 과정. 이를 통해 모델이 특정 도메인이나 응용 분야에서 더 좋은 성능을 발휘할 수 있게 됨.
    - 이를 해결하기 위한 **2가지** 방법 고안
        1. 좋은 성능의 GPU를 보유하고 있지 않기 때문에 **한국어로 튜닝된 가벼운 LLM**이 필요함. 따라서 llama3-open-ko-8B 선택
            - 이 모델은 기존 LLama3 모델 + 60GB 한국어 데이터로 추가 학습된 모델임
        2. PEFT - LoRA, 양자화
            - **PEFT (Parameter-Efficient Fine-Tuning)**: 모델 전체 파라미터를 업데이트하지 않고 일부 파라미터만 조정하여 모델을 미세 조정하는 기술. 대표적으로 LoRA, 양자화가 있음.
            - LLM finetuning 하기 위해서는 큰 용량의 VRAM이 필요함. 따라서 **LoRA**를 사용해서 1%가량의 하이퍼파라미터를 Finetuning 하여 adapter형식으로 만듦. 이후 기존 모델에 merge 작업을 한다. 이렇게 만들어진 모델은 특정 영역에서의 성능이 높아진 모델이다.{우리는 unsloth 라이브러리로 LoRA finetuning}
                - **LoRA (Low-Rank Adaptation)**: 대형 언어 모델을 효율적으로 미세 조정(fine-tuning)하는 방법. 모델의 파라미터를 전부 업데이트하는 대신, 일부 저차원(low-rank) 매트릭스만 업데이트하여 계산 비용을 줄이고, 메모리 사용량을 감소시킴
                - **Unsloth** : LLM 훈련 과정에서 병렬화, 배치 처리, 메모리 최적화 등의 기술을 적용하여 속도를 대폭 높이고 메모리 사용량을 줄이면서도 정확성은 유지하거나 향상시키는 도구. LoRA 어댑터 훈련을 지원함.{자원이 적은 우리 상황에 적합한 도구}
            - 또한, 우리가 선정한 모델은 이미 **8bit 양자화**가 된 모델임
                - **양자화 (Quantization)**: 모델의 파라미터를 더 적은 비트 수로 표현하여 메모리 사용량과 계산량을 줄이는 방법. 32비트 부동소수점을 8비트 정수로 표현하여 연산 속도를 높이고 메모리 요구사항을 줄임.
            - {이후 gguf 파일로 만들어서 lm studio에서 테스트}
5. **적용 후 무엇을 학습하려고 하는가? / 이를 위해 필요한 데이터셋은 무엇인가?**
    - 금융실명제에 관련된 지식
    - 현재 은행실무자는 은행연합회에서 발행한 금융실명거래 업무해설(16.08.)을 기준으로 업무처리를 진행함. 이에 이를 토대로 한 데이터셋을 생성하고자 함.
6. **이런 데이터셋을 만들기 위해 어떤 노력을 했는가?**
    - **기성 LLM(Chat GPT 4o)을 통해 생성(self-instruction)**: 기성 대형 언어 모델(LLM)을 활용하여 필요한 데이터셋을 생성하고, 부족한 부분을 보완하였다. (llama를 튜닝한 alpaca에서 사용된 방법)
        - 데이터셋 생성 방법 : GPT-4o에 금융실명거래 업무해설(16.08.)를 업로드 하고 QUESTION - ANSWER 형식으로 **생성**. 해당 도메인 지식을 보유한 김재현, 정민혁이 **검수**
7. **학습 데이터 및 하이퍼파라미터 선정**
    - A,B,C 데이터를 바탕으로 X,Y,Z 파라미터에 대해 학습한 모델 생성
    - 특정 평가 기준을 적용하여 가장 나은 모델 선정하는 과정 ~
8. **결과를 만들어보니 어떠한가?**
    - 몇가지 금융실명제 질문에 대한 답변 예시
    - 해당 내용과 실제 업무해설자료 내용 대조하여 증명
    - 기존 LLM(llama3, GPT 등)과 답변 내용 비교
    
    → 우리가 튜닝한 모델이 기존 모델보다 **금융실명제 관련 도메인에 특화**되었다.
    

### 결론

9. **한계점**
    - 금융 관련법 특성상 변동이 잦지 않지만, 관련법이 개정될 경우 지속적인 fine-tuning이 필요하다.
    - 원문 위치(근거자료)를 제공하기 어렵다.
    - 과거 데이터를 잊지 못하는 현상이 발생할 수 있다.
    (새로운 지식포함 fine tuning 할 경우 새로운 지식만으로 답변하는게 아니라 과거+새로운 지식으로 답변함)
    
    → 개선 방안 : RAG(검색 증강 생성) 결합 필요
    
    - **RAG (Retrieval-Augmented Generation)**: 검색 기반 생성 모델로, 정보를 생성할 때 외부 데이터베이스나 문서에서 관련 정보를 검색하여 이를 기반으로 텍스트를 생성하는 방법. 이를 통해 모델이 더 정확하고 관련성 높은 응답을 생성. (검색 기반)
    - REG+PEFT 일때 성능이 올라간다는 연구가 있음(https://inspirit941.tistory.com/509)
10. **결론**
- **제한된 자원** 속에서도 LORA를 활용하여 대규모 언어 모델(LLM)을 특정 도메인에 특화되게 튜닝했다. 모델 성능을 최적화하는 과정에서 많은 학습이 있었으며, 반복적인 하이퍼파라미터 조정을 통해 최적의 결과를 얻을 수 있었다. 
향후 이 모델이 더 개발된다면, 업무에 처음 투입된 금융실무자나 관련 도메인 지식이 부족한 일반인에게도 다양한 케이스의 금융실명제 관련 지식을 제공할 수 있을 것이다.

---

**PEFT vs RAG에서 PEFT를 선택한 이유?**

1. 금융실명거래 업무해설 이라는 문서는 QnA 형식으로 이루어져 있지 않음, 따라서 RAG 형식으로 정보를 제공했을때 다양한 케이스를 고려한 정확한 답변을 찾기 어려울 수도 있을거라고 생각함
2. 그래서 우리는 self-instruction을 통해 문서에서 QnA 형식으로 데이터셋을 추출한 뒤, 해당 도메인에 지식이 있는 사람이 직접 검수함. 이러한 데이터를 LLM에 적용해 PEFT-LoRA로 학습시키는 방향이 더 정밀한 답변을 제공할 것이라고 판단. (수업에서 배운 하이퍼파라미터 튜닝을 활용하고 싶은 마음도 조금 있었음)

### 배경 지식

### 파인튜닝이란

- **파인튜닝 (Fine-Tuning)**: 이미 학습된 모델(기본 모델)을 특정 작업이나 데이터셋에 맞게 추가 학습시키는 과정. 이를 통해 모델이 특정 도메인이나 응용 분야에서 더 좋은 성능을 발휘할 수 있게 됨

### PEFT란

- **PEFT (Parameter-Efficient Fine-Tuning)**: 모델 전체 파라미터를 업데이트하지 않고 일부 파라미터만 조정하여 모델을 미세 조정하는 다양한 기술들을 포괄하는 용어. 대표적으로 LoRA가 있음. **(Fine-Tuning 기반)**

### RAG란

- **RAG (Retrieval-Augmented Generation)**: 검색 기반 생성 모델로, 정보를 생성할 때 외부 데이터베이스나 문서에서 관련 정보를 검색하여 이를 기반으로 텍스트를 생성하는 방법. 이를 통해 모델이 더 정확하고 관련성 높은 응답을 생성. **(검색 기반)**

### LoRA/QLoRA란

- **LoRA (Low-Rank Adaptation)**: PEFT의 일종으로 대형 언어 모델을 효율적으로 미세 조정(fine-tuning)하는 방법. 모델의 파라미터를 전부 업데이트하는 대신, 일부 저차원(low-rank) 매트릭스만 업데이트하여 계산 비용을 줄이고, 메모리 사용량을 감소시킴.
- **QLoRA (Quantized LoRA)**: LoRA의 양자화 버전으로, 모델 파라미터를 양자화하여 메모리와 계산 자원을 더욱 절약하면서도 성능을 유지하는 방법

### 양자화란

- **양자화 (Quantization)**: 모델의 파라미터를 더 적은 비트 수로 표현하여 메모리 사용량과 계산량을 줄이는 방법. 예를 들어, 32비트 부동소수점을 8비트 정수로 표현하여 연산 속도를 높이고 메모리 요구사항을 줄일 수 있음

### LLaMA

- Big Tech 기업 Meta가 만든 LLM중 연구자들이 weight 수준까지 접근할 수 있는 **거의 유일한 모델**

### LLaMa3

- 현재 라마 3는 Meta 웹사이트에서 두 가지 파라미터 크기로 무료로 다운로드할 수 있음: 80억(8B)과 700억(70B). Llama 3는 다음 토큰 예측을 위한 기본 모델인 사전 학습과 사용자 명령에 맞게 미세 조정된 명령어 조정의 두 가지 버전으로 제공. 두 버전 모두 8,192개의 토큰으로 컨텍스트 제한이 있음

### **Llama-3-Open-Ko-8B**

Meta의 Llama-3 모델을 기반으로 한 한국어 특화 언어 모델. Llama-3-8B 구조를 기반으로 하고 있으며, 약 60GB의 공개된 한국어 데이터를 사용해 훈련됨(AI-Hub 대화 데이터셋 등). 95% 영어에 5% 한국어 학습된 모델이라 제대로 된 한국어 LLM을 쓰려면 추가 학습이 요구됨

### Alpaca

- 스탠퍼드 대학에서 Meta의 **LLaMA-7B** 모델을 finetuning한 모델
- Instruction-Following Model을 학습하는 방법(self-instrucion)
    - Instruction-Following Model : 사용자로부터 주어진 지시(instruction)를 이해하고 이에 따라 특정 작업을 수행하는 인공지능 모델을 의미함
    - self-instruct : 대량의 instruction 데이터셋을 LLM을 활용해 생성(저렴한 학습 비용)
        
    
### Alpaca-Lora

- 기존 알파카를 finetuning 하기 위해서는 112GB의 VRAM이 필요함. 따라서 **LoRA**를 사용해서 일부만 finetuning 하고 특정 영역에서의 성능을 끌어올림

### 알파카 템플릿이란?

- Alpaca 모델의 학습에 사용된 데이터 형식
- **목적**: LLaMA 모델을 fine tuning 할때, 명령을 특정 형식(template)으로 제공하여 모델이 더 잘 이해하고 따를 수 있도록 도움
- **예시**: 여기서 "instruction"은 모델에게 주어진 명령, "input"은 추가적인 입력(없을 수도 있음), "output"은 모델이 생성해야 할 응답.
    
    ```json
    {
      "instruction": "금융실명거래의 기본 원칙은 무엇입니까?",
      "input": "",
      "output": "금융실명거래의 기본 원칙은 모든 금융거래가 실지명의로 이루어져야 한다는 것입니다."
    }
    ```
    

### SFTTrainer란

- **SFTTrainer (Supervised Fine-Tuning Trainer)**: 지도 학습을 통해 모델을 미세 조정(fine-tuning)하는 훈련 도구. 일반 Trainer에 비해 대화형, Instruction 포멧의 데이터셋을 다루는데 보다 효율적임

### Unsloth란

- LLM 훈련 과정에서 병렬화, 배치 처리, 메모리 최적화 등의 기술을 적용하여 속도를 대폭 높이고 메모리 사용량을 줄이면서도 정확성은 유지하거나 향상시키는 도구. LoRA 어댑터 훈련을 지원함.

---
